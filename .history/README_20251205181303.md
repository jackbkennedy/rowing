# Rowing Data Scraper

A TypeScript Express server that automatically scrapes World's Toughest Row race data every 2 hours and saves it as CSV files.

## Features

- ğŸ• Automatic data scraping every 2 hours using cron jobs
- ğŸ“Š Parses HTML table data from the race tracking website
- ğŸ’¾ Saves data as CSV files with timestamps
- ğŸš€ Includes manual trigger endpoint for on-demand scraping
- ğŸ“ Maintains a `latest.csv` file with the most recent data

## Installation

```bash
npm install
```

## Build

```bash
npm run build
```

## Usage

### Development Mode

```bash
npm run dev
```

### Production Mode

```bash
npm run build
npm start
```

## Endpoints

- `GET /` - Health check endpoint
- `GET /scrape-now` - Manually trigger a data scrape

## Data Storage

All CSV files are stored in the `data/` directory:
- `rowing-data-[timestamp].csv` - Historical data files with timestamps
- `latest.csv` - Always contains the most recent scrape

## CSV Columns

- No
- Device
- Name
- Last Update (UTC)
- Latitude
- Longitude
- Speed
- Course
- Next Waypoint
- DTF (NM)
- VMG (knots)
- Scraped At

## Cron Schedule

The server runs a scrape job every 2 hours (at :00 minutes of every even hour).

The server also performs an initial scrape when it starts up.

